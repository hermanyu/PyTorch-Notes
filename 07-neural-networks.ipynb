{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d1e60b-53a0-414d-9968-8aae18f096b2",
   "metadata": {},
   "source": [
    "# Neural Networks (For Real This Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afff05ca-8f22-4e52-a683-26bdb6b4b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de694f24-a22c-4071-b754-e193d30e0518",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "First order of business: setting all our tensors to run on the GPU. So far, we've had to manually assign every single tensor to the GPU. Well not anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261ee24b-358a-45d2-895a-82d97aecf3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cofigure device which we can assign to all tensors\n",
    "device = torch.device('cuda')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e6a19-22a4-4afe-84f1-2a0e6e8a2c6c",
   "metadata": {},
   "source": [
    "---\n",
    "## The Data and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e546f9-15f6-4da0-8fb2-9c6d35a1acb5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "For our first official neural network, we'll be training on the MNIST handwritten digit data set, the \"hello, world!\" of Machine Learning Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "104aee08-e70f-4ed3-96f8-9211bb7fb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape of MNIST digits are 28 x 28 = 784 pixels in total\n",
    "input_size = 784\n",
    "\n",
    "# we'll specify the number of hidden units in the hidden layer\n",
    "hidden_size = 100\n",
    "\n",
    "# the output should consist of 10 classes: 0 - 9\n",
    "output_size = 10\n",
    "\n",
    "# set batch size\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86785890-7203-4c36-b978-addb26dcc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train data for MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "                    root='./data', # where the data is stored\n",
    "                    train=True, # whether to load training set or test set\n",
    "                    transform = transforms.ToTensor(), # preprocess each image into a tensor\n",
    "                    download=True # if missing, will download dataset\n",
    "                )\n",
    "# setup test data\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "                    root='./data', # where the data is stored\n",
    "                    train=False, # whether to load training set or test set\n",
    "                    transform = transforms.ToTensor() # preprocess each image into a tensor; Note that this also scales the 0-255 pixel values to 0 - 1, so very nice!\n",
    "                )\n",
    "\n",
    "# build dataloader for training set\n",
    "train_loader = torch.utils.data.DataLoader( dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "# build dataloader for test data\n",
    "test_loader = torch.utils.data.DataLoader( dataset = test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e791955-aab8-46d1-915f-c232a7348b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# pick out a batch from the training loader\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "\n",
    "# look at batch dimension info.\n",
    "## We should see: 100 images x 1 channel x 28 width x 28 height\n",
    "print(samples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c23df979-a772-4529-9927-c21f154c20bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0353, 0.3020, 0.9804, 0.9961, 0.9961, 0.0863, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
       "          0.6431, 0.9922, 0.9922, 0.7294, 0.4902, 0.0275, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6588,\n",
       "          0.9922, 0.9922, 0.3922, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961,\n",
       "          0.9922, 0.7490, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9490, 0.9961,\n",
       "          0.7294, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9373, 0.9922, 0.7451,\n",
       "          0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.5882, 0.9922, 0.9922, 0.4196,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3098, 0.9922, 0.9922, 0.4667, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.8000, 0.9922, 0.9020, 0.0902, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.3451, 0.9490, 0.9922, 0.5020, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0314, 0.8118, 0.9961, 0.8235, 0.0000, 0.0588, 0.1333,\n",
       "          0.1333, 0.1333, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3333, 0.9922, 0.9922, 0.6745, 0.5804, 0.8235, 1.0000,\n",
       "          0.9922, 0.9922, 0.7059, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0353, 0.7843, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961,\n",
       "          0.9922, 0.9922, 0.9922, 0.8824, 0.3490, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.9922, 0.9922, 0.9922, 0.9412, 0.7725, 0.2863, 0.2314,\n",
       "          0.0392, 0.0392, 0.7294, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.9922, 0.9922, 0.9843, 0.3059, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.2392, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.9922, 0.9922, 0.6078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.2392, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0863, 0.9804, 0.9922, 0.7255, 0.0196, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0392, 0.9216, 0.9922, 0.6275, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3490, 0.9569, 0.9922, 0.7569, 0.4784, 0.1765, 0.1765,\n",
       "          0.4784, 0.9294, 0.9922, 0.7843, 0.0863, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.6471, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961,\n",
       "          0.9922, 0.9922, 0.6627, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0471, 0.3373, 0.5608, 0.6902, 0.9922, 0.7529,\n",
       "          0.5608, 0.2039, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the samples variable should contain a batch of images, stored as a matrix\n",
    "# lets take a look at the first \"image\"\n",
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eee1ec0b-808f-474a-bd95-f02b99fc89a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.3020,\n",
       "         0.9804, 0.9961, 0.9961, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.6431, 0.9922,\n",
       "         0.9922, 0.7294, 0.4902, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6588, 0.9922, 0.9922,\n",
       "         0.3922, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961, 0.9922, 0.7490,\n",
       "         0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9490, 0.9961, 0.7294, 0.0588,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1373, 0.9373, 0.9922, 0.7451, 0.0667, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.5882, 0.9922, 0.9922, 0.4196, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.3098, 0.9922, 0.9922, 0.4667, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.8000, 0.9922, 0.9020, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3451, 0.9490, 0.9922, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0314, 0.8118, 0.9961, 0.8235, 0.0000, 0.0588, 0.1333, 0.1333, 0.1333,\n",
       "         0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3333, 0.9922, 0.9922, 0.6745, 0.5804, 0.8235, 1.0000, 0.9922, 0.9922,\n",
       "         0.7059, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
       "         0.7843, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961, 0.9922, 0.9922,\n",
       "         0.9922, 0.8824, 0.3490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
       "         0.9922, 0.9922, 0.9922, 0.9412, 0.7725, 0.2863, 0.2314, 0.0392, 0.0392,\n",
       "         0.7294, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
       "         0.9922, 0.9922, 0.9843, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2392, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
       "         0.9922, 0.9922, 0.6078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2392, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
       "         0.9804, 0.9922, 0.7255, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392,\n",
       "         0.9216, 0.9922, 0.6275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3490, 0.9569, 0.9922, 0.7569, 0.4784, 0.1765, 0.1765, 0.4784, 0.9294,\n",
       "         0.9922, 0.7843, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.6471, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961, 0.9922, 0.9922,\n",
       "         0.6627, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0471, 0.3373, 0.5608, 0.6902, 0.9922, 0.7529, 0.5608, 0.2039,\n",
       "         0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice the image is wrapped in an extra layer of brackets.\n",
    "# this extra level corresponds to the color channel.\n",
    "# For colored images we would usually see 3 sets of matrices\n",
    "# But for grayscale we only have 1 channel, hence a redundant set of brackets\n",
    "\n",
    "# we can extrac the \"image\" like so\n",
    "samples[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58437629-4ec5-48f4-a917-8ab5bec3a849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the images\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3a880-53fd-4196-b405-8ac38743553a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d606c275-f124-422f-ba34-335b69e56320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    # initialize neural network. We'll pass input size, hidden size, and output size as arguments\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # call the super().__init__() method to inherit the super class nn.Module\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        # We set-up components of the network here. This usually includes the different kinds of layers and activation functions\n",
    "        ### hidden layer 1\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size).to(device)\n",
    "        ### relu activation\n",
    "        self.relu = nn.ReLU()\n",
    "        ### output layer\n",
    "        self.output = nn.Linear(hidden_size, output_size).to(device)\n",
    "        \n",
    "    \n",
    "    # define feed-forward pass\n",
    "    def forward(self, x):\n",
    "        # chain together the previous components \n",
    "        out = self.hidden1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7252133-cc03-4b75-916c-1047d46d114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our shiny new neural network\n",
    "model = NeuralNet(input_size=input_size, hidden_size = hidden_size, output_size=output_size)\n",
    "\n",
    "# set learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# set loss and optimizer\n",
    "\n",
    "### Since we are doing multiclass classification, we'll need CrossEntropyLoss()\n",
    "### but remember for the PyTorch version: we don't need to pass a softmax activation in the output layer nor do we need to one-hot encode\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### set optimizer to Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc508656-00a9-4847-aa2e-4f6006509f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10, batch 100/600, loss = 2.8741\n",
      "epoch 1 / 10, batch 200/600, loss = 1.0155\n",
      "epoch 1 / 10, batch 300/600, loss = 0.8971\n",
      "epoch 1 / 10, batch 400/600, loss = 0.6393\n",
      "epoch 1 / 10, batch 500/600, loss = 0.9247\n",
      "epoch 1 / 10, batch 600/600, loss = 0.7078\n",
      "epoch 2 / 10, batch 100/600, loss = 0.8322\n",
      "epoch 2 / 10, batch 200/600, loss = 0.6101\n",
      "epoch 2 / 10, batch 300/600, loss = 0.6622\n",
      "epoch 2 / 10, batch 400/600, loss = 0.9467\n",
      "epoch 2 / 10, batch 500/600, loss = 0.6634\n",
      "epoch 2 / 10, batch 600/600, loss = 0.7229\n",
      "epoch 3 / 10, batch 100/600, loss = 0.4852\n",
      "epoch 3 / 10, batch 200/600, loss = 0.4067\n",
      "epoch 3 / 10, batch 300/600, loss = 0.4216\n",
      "epoch 3 / 10, batch 400/600, loss = 0.4351\n",
      "epoch 3 / 10, batch 500/600, loss = 0.6186\n",
      "epoch 3 / 10, batch 600/600, loss = 0.7298\n",
      "epoch 4 / 10, batch 100/600, loss = 0.4227\n",
      "epoch 4 / 10, batch 200/600, loss = 0.6420\n",
      "epoch 4 / 10, batch 300/600, loss = 0.3973\n",
      "epoch 4 / 10, batch 400/600, loss = 0.3420\n",
      "epoch 4 / 10, batch 500/600, loss = 0.3309\n",
      "epoch 4 / 10, batch 600/600, loss = 0.5919\n",
      "epoch 5 / 10, batch 100/600, loss = 0.4916\n",
      "epoch 5 / 10, batch 200/600, loss = 0.4486\n",
      "epoch 5 / 10, batch 300/600, loss = 0.8229\n",
      "epoch 5 / 10, batch 400/600, loss = 0.4294\n",
      "epoch 5 / 10, batch 500/600, loss = 0.3249\n",
      "epoch 5 / 10, batch 600/600, loss = 0.2289\n",
      "epoch 6 / 10, batch 100/600, loss = 0.7018\n",
      "epoch 6 / 10, batch 200/600, loss = 0.2934\n",
      "epoch 6 / 10, batch 300/600, loss = 0.3502\n",
      "epoch 6 / 10, batch 400/600, loss = 0.2988\n",
      "epoch 6 / 10, batch 500/600, loss = 0.4075\n",
      "epoch 6 / 10, batch 600/600, loss = 0.4824\n",
      "epoch 7 / 10, batch 100/600, loss = 0.3430\n",
      "epoch 7 / 10, batch 200/600, loss = 0.4950\n",
      "epoch 7 / 10, batch 300/600, loss = 0.3461\n",
      "epoch 7 / 10, batch 400/600, loss = 0.6801\n",
      "epoch 7 / 10, batch 500/600, loss = 0.1963\n",
      "epoch 7 / 10, batch 600/600, loss = 0.2463\n",
      "epoch 8 / 10, batch 100/600, loss = 0.3604\n",
      "epoch 8 / 10, batch 200/600, loss = 0.3852\n",
      "epoch 8 / 10, batch 300/600, loss = 0.2556\n",
      "epoch 8 / 10, batch 400/600, loss = 0.4056\n",
      "epoch 8 / 10, batch 500/600, loss = 0.5599\n",
      "epoch 8 / 10, batch 600/600, loss = 0.3022\n",
      "epoch 9 / 10, batch 100/600, loss = 0.2532\n",
      "epoch 9 / 10, batch 200/600, loss = 0.8622\n",
      "epoch 9 / 10, batch 300/600, loss = 0.6149\n",
      "epoch 9 / 10, batch 400/600, loss = 0.4675\n",
      "epoch 9 / 10, batch 500/600, loss = 0.4396\n",
      "epoch 9 / 10, batch 600/600, loss = 0.4831\n",
      "epoch 10 / 10, batch 100/600, loss = 0.2471\n",
      "epoch 10 / 10, batch 200/600, loss = 0.5363\n",
      "epoch 10 / 10, batch 300/600, loss = 0.4101\n",
      "epoch 10 / 10, batch 400/600, loss = 0.3626\n",
      "epoch 10 / 10, batch 500/600, loss = 0.3434\n",
      "epoch 10 / 10, batch 600/600, loss = 0.2825\n",
      "accuracy: 89.68\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "n_steps = len(train_loader)\n",
    "\n",
    "# set number of epochs to train\n",
    "num_epochs = 10\n",
    "\n",
    "# build training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # recall the train_loader spits out training data in batches\n",
    "    ### Define training loop over all batches\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # recall that image shapes are stored as a 1 x 28 x 28 tensor\n",
    "        # we need to reshape the image to 784 long vector to feed it into the input layer.\n",
    "        ### Preprocessing inputs\n",
    "        images = images.reshape(-1, 28*28).to(device)  # specify that this tensor should be on the GPU\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # feed-forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # descend\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print a console output to monitor training\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, batch {i+1}/{n_steps}, loss = {loss.item():.4f}')\n",
    "        \n",
    "    # once all the batches have been processed, the accumulated gradient can be reset for the next epoch run\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "# check accuracy on test set\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct/n_samples\n",
    "    \n",
    "    print(f'accuracy: {acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0fc43-27f1-41d1-8ec3-c2bde807d53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb6a5e-8667-45bd-8ee9-b2b01e18e613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
