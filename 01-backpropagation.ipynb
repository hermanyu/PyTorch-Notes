{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d503e5c4-c12c-40ff-8782-00365c9d475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e96e45-a508-42dc-831d-d2be9f11e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see how backpropagation works in PyTorch, let's make a toy example \"neural network\"\n",
    "\n",
    "# input value\n",
    "x = torch.tensor(1.0)\n",
    "\n",
    "# actual output label/value\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "# weights\n",
    "w = torch.tensor(1.0, requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce08583-5612-47f2-8d7f-740407dc6d4a",
   "metadata": {},
   "source": [
    "So our \"neural network\" has a single input $x$ and a single output $\\hat{y}$ with a single weigth $w$\n",
    "$$\\hat{y} = w\\cdot x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82d5139-f4fe-42b0-980f-47c875a0ebb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "y_hat = w*x\n",
    "\n",
    "# compute loss using MSE\n",
    "loss = (y_hat - y)**2\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0cea7b-5407-42e5-9f3e-04b1c5529d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute gradient of loss\n",
    "loss.backward()\n",
    "\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cb686-6efe-4711-9326-d84b1c3f65e6",
   "metadata": {},
   "source": [
    "- So the gradient is -2. Let's verify this manually:\n",
    "$$L = (\\hat{y}-y)^2$$\n",
    "$$\\frac{dL}{dw} = 2(\\hat{y}-y)\\cdot \\frac{d\\hat{y}}{dw}$$\n",
    "Recall that $\\hat{y}=w\\cdot x$, and therefore\n",
    "$$\\frac{d\\hat{y}}{dw}=x$$\n",
    "So therefore:\n",
    "$$\\frac{dL}{dw} = 2(\\hat{y}-y)\\cdot x$$\n",
    "Now, evaluating at $x=1$, $y=2$, and $w=1$, gives us:\n",
    "$$\\frac{dL}{dw} = 2(1-2)(1)=-2$$\n",
    "which is exactly what PyTorch said!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4a1c1-86df-437b-a368-2731549d5657",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c00c6-6464-4998-ab7a-a8ecd001938b",
   "metadata": {},
   "source": [
    "# An Example of Auto Differentiation\n",
    "\n",
    "Let's start by hard coding an example without using PyTorch.\n",
    "\n",
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0ca656f-834d-4372-93de-cac8ddd53206",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i*0.3 for i in range(0,20)], dtype=np.float32)\n",
    "y = np.array([2.2*i for i in range(0,20)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a20e1415-9919-4d15-8043-8ce6b646fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: weight = 3.260     ,     loss = 597.7401\n",
      "epoch 2: weight = 5.071     ,     loss = 184.3844\n",
      "epoch 3: weight = 6.077     ,     loss = 56.8769\n",
      "epoch 4: weight = 6.636     ,     loss = 17.5448\n",
      "epoch 5: weight = 6.946     ,     loss = 5.4120\n",
      "epoch 6: weight = 7.118     ,     loss = 1.6694\n",
      "epoch 7: weight = 7.214     ,     loss = 0.5150\n",
      "epoch 8: weight = 7.267     ,     loss = 0.1589\n",
      "epoch 9: weight = 7.296     ,     loss = 0.0490\n",
      "epoch 10: weight = 7.313     ,     loss = 0.0151\n",
      "epoch 11: weight = 7.322     ,     loss = 0.0047\n",
      "epoch 12: weight = 7.327     ,     loss = 0.0014\n",
      "epoch 13: weight = 7.330     ,     loss = 0.0004\n",
      "epoch 14: weight = 7.331     ,     loss = 0.0001\n",
      "epoch 15: weight = 7.332     ,     loss = 0.0000\n",
      "epoch 16: weight = 7.333     ,     loss = 0.0000\n",
      "epoch 17: weight = 7.333     ,     loss = 0.0000\n",
      "epoch 18: weight = 7.333     ,     loss = 0.0000\n",
      "epoch 19: weight = 7.333     ,     loss = 0.0000\n",
      "epoch 20: weight = 7.333     ,     loss = 0.0000\n",
      "Prediction: y = [ 0.         2.199983   4.399966   6.5999484  8.799932  10.999914\n",
      " 13.199897  15.399879  17.599863  19.799847  21.999828  24.199812\n",
      " 26.399794  28.599777  30.799759  32.999744  35.199726  37.399708\n",
      " 39.599693  41.799675 ]\n"
     ]
    }
   ],
   "source": [
    "w = 0.0\n",
    "\n",
    "# feed forward\n",
    "def forward_pass(x):\n",
    "    return (w*x)\n",
    "\n",
    "# define loss function; we use MSE\n",
    "def loss(y, y_preds):\n",
    "    return ((y_preds-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "def gradient(x, y, y_preds):\n",
    "    return np.dot(2*x, y_preds-y).mean()\n",
    "\n",
    "# training\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    y_preds = forward_pass(X)\n",
    "    # compute loss\n",
    "    L = loss(y,y_preds)\n",
    "    # compute gradient\n",
    "    grad = gradient(X,y, y_preds)\n",
    "    # descend\n",
    "    w = w - learning_rate*grad\n",
    "    \n",
    "    print(f'epoch {epoch+1}: weight = {w:.3f}     ,     loss = {L:.4f}')\n",
    "    \n",
    "predictions = forward_pass(X)\n",
    "    \n",
    "print(f'Prediction: y = {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737361ac-a40e-4c19-9b6a-4ac121af9c8d",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d2ea629-0fce-4729-9409-306d888b2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([i*0.3 for i in range(0,20)], device = 'cuda', dtype=torch.float32)\n",
    "y = torch.tensor([2.2*i for i in range(0,20)], device = 'cuda', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "865c1ffb-d62e-44d4-9f17-6370059ce977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: weight = 1.630     ,     loss = 597.7400\n",
      "epoch 2: weight = 2.898     ,     loss = 361.5235\n",
      "epoch 3: weight = 3.884     ,     loss = 218.6557\n",
      "epoch 4: weight = 4.651     ,     loss = 132.2467\n",
      "epoch 5: weight = 5.247     ,     loss = 79.9851\n",
      "epoch 6: weight = 5.711     ,     loss = 48.3764\n",
      "epoch 7: weight = 6.072     ,     loss = 29.2589\n",
      "epoch 8: weight = 6.352     ,     loss = 17.6963\n",
      "epoch 9: weight = 6.570     ,     loss = 10.7030\n",
      "epoch 10: weight = 6.740     ,     loss = 6.4734\n",
      "epoch 11: weight = 6.872     ,     loss = 3.9152\n",
      "epoch 12: weight = 6.974     ,     loss = 2.3680\n",
      "epoch 13: weight = 7.054     ,     loss = 1.4322\n",
      "epoch 14: weight = 7.116     ,     loss = 0.8662\n",
      "epoch 15: weight = 7.164     ,     loss = 0.5239\n",
      "epoch 16: weight = 7.202     ,     loss = 0.3169\n",
      "epoch 17: weight = 7.231     ,     loss = 0.1916\n",
      "epoch 18: weight = 7.254     ,     loss = 0.1159\n",
      "epoch 19: weight = 7.272     ,     loss = 0.0701\n",
      "epoch 20: weight = 7.285     ,     loss = 0.0424\n",
      "Prediction: y = tensor([ 0.0000,  2.1856,  4.3712,  6.5568,  8.7424, 10.9279, 13.1135, 15.2991,\n",
      "        17.4847, 19.6703, 21.8559, 24.0415, 26.2271, 28.4127, 30.5983, 32.7838,\n",
      "        34.9694, 37.1550, 39.3406, 41.5262], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(0.0, device='cuda', dtype = torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    y_preds = forward_pass(X)\n",
    "    # compute loss\n",
    "    L = loss(y,y_preds)\n",
    "    # compute gradient; notice PyTorch Does it for us!\n",
    "    L.backward()\n",
    "    # descend; \n",
    "    # we need be careful here: PyTorch is tracking all the computations on a graph\n",
    "    # so that it can autodifferentiate. If we try to descend by re-assigning w,\n",
    "    # it'll create a loop in the computation graph. So what we have to do is momentarily\n",
    "    # suspend the computation tracking by PyTorch\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "    \n",
    "    # reset accumulated gradient\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    print(f'epoch {epoch+1}: weight = {w:.3f}     ,     loss = {L:.4f}')\n",
    "    \n",
    "predictions = forward_pass(X)\n",
    "    \n",
    "print(f'Prediction: y = {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce65c62-d840-4b2b-b4d6-7f7045defafe",
   "metadata": {},
   "source": [
    "## So Where Are We At?\n",
    "\n",
    "Without PyTorch:\n",
    "1. Predictions / Feed-Forward: Manual.\n",
    "2. Differentiation / Backpropagation: Manual.\n",
    "3. Define Loss Function: Manual.\n",
    "4. Updata Weights: Manual.\n",
    "\n",
    "With ```tensor.backward()``` in PyTorch:\n",
    "1. Predictions / Feed-Forward: Manual.\n",
    "2. Differentiation / Backpropagation: PyTorch Autograd.\n",
    "3. Define Loss Function: Manual.\n",
    "4. Updata Weights: Manual.\n",
    "\n",
    "Looking ahead:\n",
    "1. Predictions / Feed-Forward: PyTorch Model.\n",
    "2. Differentiation / Backpropagation: Manual.\n",
    "3. Define Loss Function: PyTorch Loss.\n",
    "4. Updata Weights: PyTorch Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbb73b-4337-4a08-8732-8f785ef9f7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
