{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd395e9-63ae-4ff4-9313-763f6ed19b27",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd8077e-d6ea-4e93-bf26-14fd8d72b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a531932d-411e-4182-a8b1-63bf00c7e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedbc2f-44c6-4081-ad13-c079664c45df",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We will be using the CIFAR-10 data set which is a multiclass image classification dataset with 10 classes.\n",
    "\n",
    "The dataset will have ```PILImage``` images of range 0 to 1. We'll transform the tensors to range -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e85faccb-1b88-41de-bceb-ca1424aee0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(), # converts PIL to tensor and also scales the pixel values\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalizes RGB channel values z = x-mean/std\n",
    "            ])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "                    root='./data', \n",
    "                    train=True,\n",
    "                    download=True,\n",
    "                    transform = transform\n",
    "                )\n",
    "\n",
    "test_dataset = train_dataset = torchvision.datasets.CIFAR10(\n",
    "                    root='./data', \n",
    "                    train=False,\n",
    "                    transform = transform\n",
    "                )\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66a63b20-dcc6-411c-ab67-a20aef3176e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.0667,  0.0980,  0.1137,  ...,  0.5373,  0.4902,  0.4588],\n",
       "           [ 0.0510,  0.0824,  0.0980,  ...,  0.4431,  0.4039,  0.3725],\n",
       "           [-0.0118,  0.0196,  0.0431,  ...,  0.3255,  0.3176,  0.3098],\n",
       "           ...,\n",
       "           [-0.3725, -0.3647, -0.3647,  ..., -0.4353, -0.4353, -0.4588],\n",
       "           [-0.3569, -0.3569, -0.3569,  ..., -0.4353, -0.4588, -0.4745],\n",
       "           [-0.3725, -0.3804, -0.3725,  ..., -0.4275, -0.4431, -0.4902]],\n",
       " \n",
       "          [[ 0.1765,  0.2078,  0.2235,  ...,  0.5922,  0.5373,  0.5216],\n",
       "           [ 0.1608,  0.1922,  0.2157,  ...,  0.5059,  0.4588,  0.4431],\n",
       "           [ 0.0980,  0.1294,  0.1529,  ...,  0.3961,  0.3804,  0.3961],\n",
       "           ...,\n",
       "           [-0.4353, -0.4275, -0.4275,  ..., -0.4745, -0.4745, -0.4902],\n",
       "           [-0.4196, -0.4196, -0.4196,  ..., -0.4745, -0.4980, -0.5059],\n",
       "           [-0.4353, -0.4431, -0.4275,  ..., -0.4667, -0.4824, -0.5216]],\n",
       " \n",
       "          [[ 0.5451,  0.5686,  0.5843,  ...,  0.8588,  0.8275,  0.8118],\n",
       "           [ 0.5294,  0.5608,  0.5843,  ...,  0.8118,  0.7882,  0.7725],\n",
       "           [ 0.4667,  0.4980,  0.5216,  ...,  0.7333,  0.7412,  0.7412],\n",
       "           ...,\n",
       "           [-0.4588, -0.4510, -0.4510,  ..., -0.5216, -0.5294, -0.5294],\n",
       "           [-0.4431, -0.4431, -0.4431,  ..., -0.5216, -0.5451, -0.5451],\n",
       "           [-0.4588, -0.4667, -0.4510,  ..., -0.5059, -0.5294, -0.5608]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 0.9451,  0.9686,  0.9765,  ...,  0.9529,  0.9608,  0.9529],\n",
       "           [ 0.9686,  0.9843,  0.9922,  ...,  0.9686,  0.9686,  0.9686],\n",
       "           ...,\n",
       "           [-0.2157, -0.1843, -0.1216,  ..., -0.2157, -0.3490, -0.4275],\n",
       "           [-0.3412, -0.2000, -0.0510,  ..., -0.2392, -0.3176, -0.3725],\n",
       "           [-0.3490, -0.1765, -0.1059,  ..., -0.2549, -0.3020, -0.3725]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 0.9451,  0.9608,  0.9686,  ...,  0.9373,  0.9451,  0.9373],\n",
       "           [ 0.9686,  0.9686,  0.9765,  ...,  0.9529,  0.9529,  0.9529],\n",
       "           ...,\n",
       "           [-0.0824, -0.0824, -0.0275,  ..., -0.0824, -0.2157, -0.3098],\n",
       "           [-0.2000, -0.0824,  0.0588,  ..., -0.1137, -0.1922, -0.2549],\n",
       "           [-0.2235, -0.0824, -0.0275,  ..., -0.1451, -0.1922, -0.2706]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 0.9608,  0.9765,  0.9373,  ...,  0.9608,  0.9608,  0.9608],\n",
       "           [ 0.9843,  0.9922,  0.9529,  ...,  0.9765,  0.9765,  0.9765],\n",
       "           ...,\n",
       "           [-0.6784, -0.6471, -0.6157,  ..., -0.7176, -0.8196, -0.8431],\n",
       "           [-0.8745, -0.7176, -0.6000,  ..., -0.7098, -0.7804, -0.7647],\n",
       "           [-0.7569, -0.5686, -0.5294,  ..., -0.6314, -0.6863, -0.6784]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1608, -0.0824, -0.3647,  ...,  0.9686,  0.9765,  0.9608],\n",
       "           [-0.1059, -0.0588, -0.0275,  ...,  0.9922,  0.9922,  0.9765],\n",
       "           [ 0.1294,  0.0824,  0.4196,  ...,  0.9765,  0.9765,  0.9922],\n",
       "           ...,\n",
       "           [ 1.0000,  0.9373,  0.9294,  ...,  0.8588,  0.8745,  0.8902],\n",
       "           [ 1.0000,  0.9608,  0.8980,  ...,  0.8667,  0.8510,  0.8431],\n",
       "           [ 0.9216,  0.8745,  0.8431,  ...,  0.9451,  0.9059,  0.9137]],\n",
       " \n",
       "          [[ 0.1843,  0.0902, -0.1137,  ...,  0.6078,  0.5765,  0.4980],\n",
       "           [ 0.0431,  0.0980,  0.0667,  ...,  0.6549,  0.6157,  0.5529],\n",
       "           [ 0.1451,  0.0824,  0.3176,  ...,  0.6549,  0.6235,  0.6078],\n",
       "           ...,\n",
       "           [ 0.8275,  0.7725,  0.7725,  ...,  0.6314,  0.6314,  0.6314],\n",
       "           [ 0.8745,  0.8353,  0.7725,  ...,  0.6392,  0.6235,  0.6157],\n",
       "           [ 0.8275,  0.7882,  0.7647,  ...,  0.7333,  0.6941,  0.7176]],\n",
       " \n",
       "          [[-0.1451, -0.2784, -0.4980,  ...,  0.2549,  0.2392,  0.1843],\n",
       "           [-0.3020, -0.2627, -0.2863,  ...,  0.2941,  0.2706,  0.2235],\n",
       "           [-0.2000, -0.2706, -0.0353,  ...,  0.3020,  0.2784,  0.2784],\n",
       "           ...,\n",
       "           [ 0.5843,  0.5137,  0.4902,  ...,  0.3647,  0.3725,  0.3725],\n",
       "           [ 0.6078,  0.5686,  0.4824,  ...,  0.3725,  0.3569,  0.3490],\n",
       "           [ 0.5529,  0.4980,  0.4588,  ...,  0.4667,  0.4275,  0.4353]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.9686,  0.9216,  0.9137,  ...,  0.8667,  0.8745,  0.8588],\n",
       "           [ 0.9922,  0.9686,  0.9765,  ...,  0.8824,  0.8431,  0.7725],\n",
       "           [ 0.9451,  0.9608,  0.9529,  ...,  0.7020,  0.3961,  0.5137],\n",
       "           ...,\n",
       "           [-0.3333, -0.3647, -0.3569,  ..., -0.2314, -0.2549, -0.2706],\n",
       "           [-0.3569, -0.3647, -0.3490,  ..., -0.2784, -0.3020, -0.3098],\n",
       "           [-0.3804, -0.3882, -0.3882,  ..., -0.3255, -0.3333, -0.3569]],\n",
       " \n",
       "          [[ 1.0000,  0.9451,  0.9373,  ...,  0.9059,  0.9216,  0.9059],\n",
       "           [ 1.0000,  0.9922,  1.0000,  ...,  0.9294,  0.8980,  0.8196],\n",
       "           [ 0.9765,  0.9922,  0.9843,  ...,  0.7647,  0.4588,  0.5765],\n",
       "           ...,\n",
       "           [-0.5529, -0.5843, -0.5765,  ..., -0.3882, -0.4118, -0.4275],\n",
       "           [-0.5686, -0.5765, -0.5608,  ..., -0.4275, -0.4510, -0.4667],\n",
       "           [-0.5765, -0.5843, -0.5765,  ..., -0.4667, -0.4667, -0.4902]],\n",
       " \n",
       "          [[ 1.0000,  0.9686,  0.9686,  ...,  0.9216,  0.9294,  0.9059],\n",
       "           [ 1.0000,  0.9765,  0.9608,  ...,  0.9765,  0.9451,  0.8980],\n",
       "           [ 0.9843,  0.9608,  0.9137,  ...,  0.8902,  0.6000,  0.7333],\n",
       "           ...,\n",
       "           [-0.7490, -0.7725, -0.7647,  ..., -0.6000, -0.6235, -0.6392],\n",
       "           [-0.7647, -0.7725, -0.7569,  ..., -0.6392, -0.6627, -0.6784],\n",
       "           [-0.7725, -0.7804, -0.7725,  ..., -0.6784, -0.6863, -0.7098]]],\n",
       " \n",
       " \n",
       "         [[[ 0.5608,  0.5765,  0.4980,  ...,  0.6078,  0.6000,  0.5137],\n",
       "           [ 0.5137,  0.6000,  0.3961,  ...,  0.4039,  0.2941,  0.1059],\n",
       "           [ 0.2863,  0.2314,  0.2157,  ...,  0.2471,  0.2000,  0.1137],\n",
       "           ...,\n",
       "           [ 0.4824,  0.4275,  0.4510,  ...,  0.1608,  0.4667,  0.2392],\n",
       "           [ 0.4353,  0.4039,  0.4667,  ...,  0.2078,  0.2784,  0.1451],\n",
       "           [ 0.4745,  0.4667,  0.4431,  ...,  0.2078,  0.1059,  0.2235]],\n",
       " \n",
       "          [[ 0.5294,  0.5216,  0.4196,  ...,  0.5216,  0.5373,  0.4353],\n",
       "           [ 0.4588,  0.5529,  0.3490,  ...,  0.2941,  0.1843, -0.0118],\n",
       "           [ 0.1922,  0.1373,  0.1216,  ...,  0.1137,  0.0275, -0.0431],\n",
       "           ...,\n",
       "           [ 0.2706,  0.2000,  0.2078,  ..., -0.0588,  0.2314, -0.0275],\n",
       "           [ 0.2314,  0.1922,  0.2471,  ..., -0.0196,  0.0118, -0.1137],\n",
       "           [ 0.2392,  0.2235,  0.1765,  ..., -0.0196, -0.1216,  0.0588]],\n",
       " \n",
       "          [[ 0.4902,  0.4588,  0.3490,  ...,  0.4745,  0.4980,  0.4039],\n",
       "           [ 0.4275,  0.5137,  0.3098,  ...,  0.2863,  0.1608, -0.0196],\n",
       "           [ 0.1686,  0.1373,  0.1373,  ...,  0.1059,  0.0196, -0.0275],\n",
       "           ...,\n",
       "           [ 0.1294,  0.0510,  0.0588,  ..., -0.0824,  0.1843, -0.0902],\n",
       "           [ 0.0588,  0.0118,  0.0667,  ..., -0.0588, -0.0510, -0.1529],\n",
       "           [ 0.0745,  0.0510,  0.0039,  ..., -0.0667, -0.1608,  0.0510]]],\n",
       " \n",
       " \n",
       "         [[[-0.8431, -0.7176, -0.6235,  ..., -0.6157, -0.5451, -0.6784],\n",
       "           [-0.8196, -0.7098, -0.6471,  ..., -0.5922, -0.5922, -0.7647],\n",
       "           [-0.8039, -0.7255, -0.6784,  ..., -0.4980, -0.6078, -0.7569],\n",
       "           ...,\n",
       "           [-0.6235, -0.5294, -0.5373,  ...,  0.0980, -0.1843, -0.7098],\n",
       "           [-0.6706, -0.4824, -0.4118,  ...,  0.0980, -0.2078, -0.7412],\n",
       "           [-0.6941, -0.4510, -0.4039,  ...,  0.0745, -0.3490, -0.7569]],\n",
       " \n",
       "          [[-0.7882, -0.6549, -0.5529,  ..., -0.5922, -0.5216, -0.6706],\n",
       "           [-0.7569, -0.6549, -0.5765,  ..., -0.5686, -0.5686, -0.7490],\n",
       "           [-0.7412, -0.6784, -0.6235,  ..., -0.4824, -0.5843, -0.7412],\n",
       "           ...,\n",
       "           [-0.5765, -0.4902, -0.5059,  ...,  0.1686, -0.1059, -0.6706],\n",
       "           [-0.6235, -0.4275, -0.3490,  ...,  0.1765, -0.1294, -0.6941],\n",
       "           [-0.6549, -0.3804, -0.3098,  ...,  0.1451, -0.2706, -0.7098]],\n",
       " \n",
       "          [[-0.8588, -0.8039, -0.8118,  ..., -0.7176, -0.6784, -0.7412],\n",
       "           [-0.8588, -0.7882, -0.8118,  ..., -0.7020, -0.7255, -0.8118],\n",
       "           [-0.8667, -0.7961, -0.7882,  ..., -0.6706, -0.7804, -0.8039],\n",
       "           ...,\n",
       "           [-0.6784, -0.5608, -0.5608,  ...,  0.1922, -0.1294, -0.7176],\n",
       "           [-0.6941, -0.4745, -0.3961,  ...,  0.1922, -0.1608, -0.7412],\n",
       "           [-0.6941, -0.4118, -0.3412,  ...,  0.1686, -0.3020, -0.7569]]]]),\n",
       " tensor([9, 0, 7, 9, 4, 1, 6, 8])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = iter(train_loader).next()\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae6ae57-e06d-448e-a3f4-de01e016bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class labels\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2751cf5a-e80a-4167-80e9-8fa4674276bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our CNN\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # convolutional and pooling layers\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                        in_channels = 3,  # number of input channels\n",
    "                        out_channels = 6,  # number of channels outputted; equivalent to \"filters\" from Keras\n",
    "                        kernel_size= 5,  # size of the convolutional kernel\n",
    "                        device='cuda'\n",
    "                    )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2) # kernel_size and stride\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "                        in_channels = 6,\n",
    "                        out_channels = 16,\n",
    "                        kernel_size = 5,\n",
    "                        device='cuda'\n",
    "                    )\n",
    "        \n",
    "        # hidden layers\n",
    "        self.hidden1 = nn.Linear(16*5*5, 120, device='cuda')\n",
    "        self.hidden2 = nn.Linear(120, 84, device='cuda')\n",
    "        self.output = nn.Linear(84, 10, device='cuda')\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d20311a8-37b1-494d-b24e-fb5fbff691f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvNet()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr = learning_rate, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b12cd2db-6a22-4146-8c57-ee36a15815dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, batch 100/1250, loss = 2.304778971672058\n",
      "epoch 1/5, batch 200/1250, loss = 2.304095549583435\n",
      "epoch 1/5, batch 300/1250, loss = 2.305702602863312\n",
      "epoch 1/5, batch 400/1250, loss = 2.300153121948242\n",
      "epoch 1/5, batch 500/1250, loss = 2.299937663078308\n",
      "epoch 1/5, batch 600/1250, loss = 2.298501777648926\n",
      "epoch 1/5, batch 700/1250, loss = 2.29862229347229\n",
      "epoch 1/5, batch 800/1250, loss = 2.295178837776184\n",
      "epoch 1/5, batch 900/1250, loss = 2.2920383548736574\n",
      "epoch 1/5, batch 1000/1250, loss = 2.2877686476707457\n",
      "epoch 1/5, batch 1100/1250, loss = 2.273166217803955\n",
      "epoch 1/5, batch 1200/1250, loss = 2.2448321557044983\n",
      "epoch 2/5, batch 100/1250, loss = 2.1740983891487122\n",
      "epoch 2/5, batch 200/1250, loss = 2.1467120957374575\n",
      "epoch 2/5, batch 300/1250, loss = 2.0654223418235778\n",
      "epoch 2/5, batch 400/1250, loss = 2.11178759098053\n",
      "epoch 2/5, batch 500/1250, loss = 2.0577013051509856\n",
      "epoch 2/5, batch 600/1250, loss = 2.017982339859009\n",
      "epoch 2/5, batch 700/1250, loss = 2.0065340876579283\n",
      "epoch 2/5, batch 800/1250, loss = 2.002264132499695\n",
      "epoch 2/5, batch 900/1250, loss = 1.9904603457450867\n",
      "epoch 2/5, batch 1000/1250, loss = 1.9937813878059387\n",
      "epoch 2/5, batch 1100/1250, loss = 1.9968113374710084\n",
      "epoch 2/5, batch 1200/1250, loss = 1.9670861768722534\n",
      "epoch 3/5, batch 100/1250, loss = 1.9541644310951234\n",
      "epoch 3/5, batch 200/1250, loss = 1.9362129282951355\n",
      "epoch 3/5, batch 300/1250, loss = 1.8617061543464661\n",
      "epoch 3/5, batch 400/1250, loss = 1.8998246932029725\n",
      "epoch 3/5, batch 500/1250, loss = 1.866629375219345\n",
      "epoch 3/5, batch 600/1250, loss = 1.8228667223453523\n",
      "epoch 3/5, batch 700/1250, loss = 1.8219968271255493\n",
      "epoch 3/5, batch 800/1250, loss = 1.8015951466560365\n",
      "epoch 3/5, batch 900/1250, loss = 1.8000474083423614\n",
      "epoch 3/5, batch 1000/1250, loss = 1.7736949729919433\n",
      "epoch 3/5, batch 1100/1250, loss = 1.793656566143036\n",
      "epoch 3/5, batch 1200/1250, loss = 1.7290020310878753\n",
      "epoch 4/5, batch 100/1250, loss = 1.7480521714687347\n",
      "epoch 4/5, batch 200/1250, loss = 1.690288484096527\n",
      "epoch 4/5, batch 300/1250, loss = 1.6799573194980622\n",
      "epoch 4/5, batch 400/1250, loss = 1.6492627161741258\n",
      "epoch 4/5, batch 500/1250, loss = 1.6592123842239381\n",
      "epoch 4/5, batch 600/1250, loss = 1.6938902074098587\n",
      "epoch 4/5, batch 700/1250, loss = 1.6258056962490082\n",
      "epoch 4/5, batch 800/1250, loss = 1.6676762473583222\n",
      "epoch 4/5, batch 900/1250, loss = 1.645779013633728\n",
      "epoch 4/5, batch 1000/1250, loss = 1.6349480211734773\n",
      "epoch 4/5, batch 1100/1250, loss = 1.655914261341095\n",
      "epoch 4/5, batch 1200/1250, loss = 1.6105031162500383\n",
      "epoch 5/5, batch 100/1250, loss = 1.5896366035938263\n",
      "epoch 5/5, batch 200/1250, loss = 1.5647526103258134\n",
      "epoch 5/5, batch 300/1250, loss = 1.6147787433862686\n",
      "epoch 5/5, batch 400/1250, loss = 1.5605482542514801\n",
      "epoch 5/5, batch 500/1250, loss = 1.5790774786472321\n",
      "epoch 5/5, batch 600/1250, loss = 1.5899845790863036\n",
      "epoch 5/5, batch 700/1250, loss = 1.5694140475988387\n",
      "epoch 5/5, batch 800/1250, loss = 1.5522571307420732\n",
      "epoch 5/5, batch 900/1250, loss = 1.587179274559021\n",
      "epoch 5/5, batch 1000/1250, loss = 1.623402417898178\n",
      "epoch 5/5, batch 1100/1250, loss = 1.540848444700241\n",
      "epoch 5/5, batch 1200/1250, loss = 1.5127634102106096\n",
      "val accuracy: 45.68\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# define training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        inputs, labels = data\n",
    "        # we have to send the input and labels to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # feed forward\n",
    "        outputs = cnn(inputs)\n",
    "        # compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        # descend\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss computed as the average loss over every 100 batches\n",
    "        running_loss += loss.item()\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, batch {i+1}/{len(train_loader)}, loss = {running_loss*0.01}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            \n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = cnn(inputs)\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100*n_correct/n_samples\n",
    "    \n",
    "    print(f'val accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4146ed4-a16a-414a-b1b5-884ce316d851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
